{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "65c330c7-2d99-46ec-ae5a-b60b68501079",
   "metadata": {},
   "source": [
    "# Missing Values\n",
    "\n",
    "In this section, we'll be learning different missing value imputation techniques by analyzing simulated customer lifetime value data. Customer Lifetime Value is the total monetary worth the customer has to the business, over the course of its business-customer relationship. In this dataset, to keep things simple, we'll be using purchases as a proxy for CLV. \n",
    "\n",
    "We'll be covering how to:\n",
    "\n",
    "- Check the number of null values\n",
    "\n",
    "- Dropping Null Values\n",
    "\n",
    "- Mean/Median/Mode Imputation\n",
    "\n",
    "- Multiple Imputation using Regression\n",
    "\n",
    "- Imputation using Nearest Neighbors\n",
    "\n",
    "Let's get started!\n",
    "\n",
    "## Import Libraries\n",
    "\n",
    "First, we'll need to import the relevant libraries. We'll be using the standard `pandas`, `numpy` libraries for data manipulation. We'll then be using `sklearn` for the more advanced imputation techniques. We will use `scipy` for the `mode` imputation later on:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "94c9ea37-dec9-47d8-ae2c-4604c053f704",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy import stats\n",
    "from sklearn.experimental import enable_iterative_imputer\n",
    "from sklearn.impute import IterativeImputer, KNNImputer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fa274d3-cdea-4fd3-ad7d-178a810a5247",
   "metadata": {},
   "source": [
    "## Load Data\n",
    "\n",
    "We load our customer lifetime value dataset. we have about 6 columns. The `purchases` column is the column we care about in our customer lifetime value problem. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "85a145a0-b577-4024-ad1b-6af9a64c5b26",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>id</th>\n",
       "      <th>age</th>\n",
       "      <th>gender</th>\n",
       "      <th>income</th>\n",
       "      <th>days_on_platform</th>\n",
       "      <th>city</th>\n",
       "      <th>purchases</th>\n",
       "      <th>lifetime_value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Male</td>\n",
       "      <td>126895</td>\n",
       "      <td>14.0</td>\n",
       "      <td>San Francisco</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Male</td>\n",
       "      <td>161474</td>\n",
       "      <td>14.0</td>\n",
       "      <td>Tokyo</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>24.0</td>\n",
       "      <td>Male</td>\n",
       "      <td>104723</td>\n",
       "      <td>34.0</td>\n",
       "      <td>London</td>\n",
       "      <td>1</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>29.0</td>\n",
       "      <td>Male</td>\n",
       "      <td>43791</td>\n",
       "      <td>28.0</td>\n",
       "      <td>London</td>\n",
       "      <td>2</td>\n",
       "      <td>40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>18.0</td>\n",
       "      <td>Female</td>\n",
       "      <td>132181</td>\n",
       "      <td>26.0</td>\n",
       "      <td>London</td>\n",
       "      <td>2</td>\n",
       "      <td>40</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0  id   age  gender  income  days_on_platform           city  \\\n",
       "0           0   0   NaN    Male  126895              14.0  San Francisco   \n",
       "1           1   1   NaN    Male  161474              14.0          Tokyo   \n",
       "2           2   2  24.0    Male  104723              34.0         London   \n",
       "3           3   3  29.0    Male   43791              28.0         London   \n",
       "4           4   4  18.0  Female  132181              26.0         London   \n",
       "\n",
       "   purchases  lifetime_value  \n",
       "0          0               0  \n",
       "1          0               0  \n",
       "2          1              20  \n",
       "3          2              40  \n",
       "4          2              40  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import random\n",
    "\n",
    "df = pd.read_csv(\"clv_data.csv\")\n",
    "df['lifetime_value'] = df['purchases'] * 20\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6e446aed-c01c-46b9-a8a8-24b6e78bfda1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "22"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random.randint(5,50)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34ea7fde-7946-421d-a5ce-a57b171e6aee",
   "metadata": {},
   "source": [
    "## Checking Null Values\n",
    "\n",
    "The first step in any data analysis or ML model is to check null values. We can check the number of nulls in a single line:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "29a5ff25-add8-48e9-a244-9428fbb7c040",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Unnamed: 0             0\n",
       "id                     0\n",
       "age                 2446\n",
       "gender                 0\n",
       "income                 0\n",
       "days_on_platform     141\n",
       "city                   0\n",
       "purchases              0\n",
       "lifetime_value         0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17b554f9-0d88-4a48-ab1e-919894347646",
   "metadata": {},
   "source": [
    "### Percentages of NULL values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e2dbd9b8-7285-4894-bf9d-a936c759414a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>null_count</th>\n",
       "      <th>null_pct</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>age</th>\n",
       "      <td>2446</td>\n",
       "      <td>0.4892</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gender</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>income</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>days_on_platform</th>\n",
       "      <td>141</td>\n",
       "      <td>0.0282</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>city</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>purchases</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lifetime_value</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  null_count  null_pct\n",
       "Unnamed: 0                 0    0.0000\n",
       "id                         0    0.0000\n",
       "age                     2446    0.4892\n",
       "gender                     0    0.0000\n",
       "income                     0    0.0000\n",
       "days_on_platform         141    0.0282\n",
       "city                       0    0.0000\n",
       "purchases                  0    0.0000\n",
       "lifetime_value             0    0.0000"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def nulls_summary_table(df):\n",
    "    \"\"\"\n",
    "    Returns a summary table showing null value counts and percentage\n",
    "    \n",
    "    Parameters:\n",
    "    df (DataFrame): Dataframe to check\n",
    "    \n",
    "    Returns:\n",
    "    null_values (DataFrame)\n",
    "    \"\"\"\n",
    "    null_values = pd.DataFrame(df.isnull().sum())\n",
    "    null_values[1] = null_values[0]/len(df)\n",
    "    null_values.columns = ['null_count','null_pct']\n",
    "    return null_values\n",
    "\n",
    "nulls_summary_table(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23d265e6-ffae-4360-a66c-255d3e323d86",
   "metadata": {},
   "source": [
    "### Dropping Null Values\n",
    "\n",
    "Dropping nulls is the quickest and easiest method to dropping nulls. We will use the internal pandas method `dropna` which will simply drop all rows that contain nulls:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f1e211eb-2c9d-4eee-80d5-70d0799a0e7e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Unnamed: 0          0\n",
       "id                  0\n",
       "age                 0\n",
       "gender              0\n",
       "income              0\n",
       "days_on_platform    0\n",
       "city                0\n",
       "purchases           0\n",
       "lifetime_value      0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "drop_df = df.copy()\n",
    "drop_df = drop_df.dropna()\n",
    "drop_df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "34180781-9e9e-4027-a391-992c1ebefc84",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_d = drop_df[['age','days_on_platform','income']]\n",
    "y_d = drop_df['lifetime_value']\n",
    "\n",
    "X_train_d = X_d[:4000]\n",
    "y_train_d = y_d[:4000]\n",
    "\n",
    "X_test_d = X_d[1000:]\n",
    "y_test_d = y_d[1000:]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fbeec33-5d6b-4ad2-9966-5628c1a9fbbe",
   "metadata": {},
   "source": [
    "### Mean/Median/Mode Imputation\n",
    "\n",
    "The next is mean/median/mode imputation. We can use the native numpy functions for the mean and median. We can use scipy for the mode. Then, pandas as a native `fillna` method we can use to impute the nulls with the mean/median/mode:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c9840ea3-9557-4de0-bf55-a6b306dbadcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "m_df = df.copy()\n",
    "\n",
    "X_m = m_df[['age','days_on_platform','income']]\n",
    "y_m = m_df['lifetime_value']\n",
    "\n",
    "\n",
    "X_train_m = X_m[:4000]\n",
    "y_train_m = y_m[:4000]\n",
    "\n",
    "X_test_m = X_m[1000:]\n",
    "y_test_m = y_m[1000:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "665cc792-cd86-44f9-87f2-f81e6fcb76ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Mean\n",
    "X_train_m.loc[:,'age'] = X_train_m['age'].fillna(np.mean(X_train_m['age']))\n",
    "X_test_m.loc[:,'age'] = X_test_m['age'].fillna(np.mean(X_train_m['age'])) ## Cannot use training dataset to impute\n",
    "\n",
    "\n",
    "X_train_m.loc[:,'days_on_platform'] = X_train_m['days_on_platform'].fillna(np.mean(X_train_m['days_on_platform']))\n",
    "X_test_m.loc[:,'days_on_platform'] = X_test_m['days_on_platform'].fillna(np.mean(X_train_m['days_on_platform'])) ## Cannot use training dataset to impute"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8653124b-2c67-4292-a565-647041e9b131",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Median\n",
    "m_df.loc[:,'age'] = df['age'].fillna(np.median(m_df['age']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "83a4c03e-ec84-4806-bf74-54869170448b",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Mode\n",
    "m_df.loc[:,'age'] = m_df['age'].fillna(stats.mode(m_df['age'], keepdims=True).mode[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfb6951d-d80a-45c3-8bfe-ae95e1eed579",
   "metadata": {},
   "source": [
    "### Multiple Imputation Using Regression\n",
    "\n",
    "Now that we've covered the simpler imputation techniques, we'll cover a more complicated imputation technique: Multiple Imputation.\n",
    "\n",
    "Multiple imputation has a few different estimators, using the `estimator` argument:\n",
    "\n",
    "- `BayesianRidge`: Regularized Linear Regression\n",
    "\n",
    "- `RandomForestRegressor`: Random Forest Model. Mimics missForest in the R language.\n",
    "\n",
    "The `missing_values` argument is a placeholder for the data type of the missing values we want to impute. \n",
    "\n",
    "It's important to use `add_indicatorbool` as it'll create a placeholder indicating that we've imputed a missing value. This is important, because there could be patterns behind how a value is missing. Adding an indicator would allow us to keep track of where we made an imputation. Plus, it could also add signal into your model. \n",
    "\n",
    "`max_iter`: The number of iteration rounds."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "c6d6ea47-37a8-441e-9804-0ae6a150d29c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.experimental import enable_iterative_imputer\n",
    "from sklearn.impute import IterativeImputer, KNNImputer\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "## Target - Purchases in the first six months\n",
    "\n",
    "r_df = df.copy()\n",
    "\n",
    "X_r = r_df[['age','days_on_platform','income']]\n",
    "y_r = r_df['lifetime_value']\n",
    "\n",
    "\n",
    "X_train_r = X_r[:4000]\n",
    "y_train_r = y_r[:4000]\n",
    "\n",
    "X_test_r = X_r[1000:]\n",
    "y_test_r = y_r[1000:]\n",
    "\n",
    "\n",
    "Imp = IterativeImputer(estimator=LinearRegression(), max_iter=10, random_state = 0)\n",
    "Imp.fit(X_train_r)\n",
    "\n",
    "X_train_r = Imp.transform(X_train_r)\n",
    "X_test_r = Imp.transform(X_test_r)\n",
    "\n",
    "X_train_r = pd.DataFrame(X_train_r)\n",
    "X_train_r.columns = X_train_r.columns\n",
    "\n",
    "X_test_r = pd.DataFrame(X_test_r)\n",
    "X_test_r.columns = X_test_r.columns\n",
    "\n",
    "r_df = pd.concat([X_train_r,X_test_r],axis = 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "092b4352-4ab4-405c-8fd3-7bb64fb2b75f",
   "metadata": {},
   "source": [
    "### Nearest Neighbor Imputation\n",
    "\n",
    "On top of using linear regression or random forest regression to impute values, we can also use nearest neighbors imputation. Nearest neighbor imputation essentially uses a K-Nearest Neighbors algorithm to find the most similar data points, to impute the null values. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "e739cb16-845a-4a5f-834a-566fbc345dd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "imputer = KNNImputer(n_neighbors=5, weights=\"uniform\")\n",
    "imputer.fit(X_train_r)\n",
    "X_train_k = imputer.transform(X_train_r)\n",
    "X_test_k = imputer.transform(X_test_r)\n",
    "\n",
    "y_train_k = y_train_r.copy()\n",
    "y_test_k = y_test_r.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5de6e37-a65b-452e-914a-c93d5ee0d89c",
   "metadata": {},
   "source": [
    "## Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "3e96bd7c-be27-4eec-b9cd-37478ab7ba85",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Drop Null MAE Score: 7.636\n",
      "Mean Impute MAE Score: 10.828\n",
      "Regression MAE Score: 10.785 \n",
      "Nearest Neighbor MAE Score: 10.785\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "\n",
    "# Drop Null Model\n",
    "clf_n = RandomForestRegressor(random_state=0)\n",
    "clf_n.fit(X_train_d, y_train_d)\n",
    "pred_dropna = clf_n.predict(X_test_d)\n",
    "\n",
    "# Mean Imputation Model\n",
    "clf_m = RandomForestRegressor(random_state=0)\n",
    "clf_m.fit(X_train_m, y_train_m)\n",
    "pred_m = clf_m.predict(X_test_m)\n",
    "\n",
    "# Regression Imputation\n",
    "clf_r = RandomForestRegressor(random_state=0)\n",
    "clf_r.fit(X_train_r, y_train_r)\n",
    "pred_r = clf_r.predict(X_test_r)\n",
    "\n",
    "#Nearest Neighbor Imputation\n",
    "clf_n = RandomForestRegressor(random_state=0)\n",
    "clf_n.fit(X_train_k, y_train_k)\n",
    "pred_k = clf_n.predict(X_test_k)\n",
    "\n",
    "\n",
    "print('Drop Null MAE Score: %.3f' % mean_absolute_error(y_test_d,pred_dropna))\n",
    "print('Mean Impute MAE Score: %.3f' % mean_absolute_error(y_test_m,pred_m))\n",
    "print('Regression MAE Score: %.3f '% mean_absolute_error(y_test_r,pred_r))\n",
    "print('Nearest Neighbor MAE Score: %.3f'% mean_absolute_error(y_test_k,pred_k))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e9be1fc-f52e-40c6-b9ae-7b0d15eee16f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
